{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d1d974d-93f7-4973-8e7c-099f9c2ce76a",
   "metadata": {},
   "source": [
    "## OFFERED_URL 변수에는 수업에서 제공해준 url로 기입하여 주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d67206-0676-4136-bbbb-29b0e82a6c53",
   "metadata": {},
   "source": [
    "## MOBIUS_AE_NAME 변수에는 \"학번ae\" 형식으로 기입하여 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4303203d-b0bb-402e-987a-715bc096c551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 시드 고정 (재현성)\n",
    "# --------------------------------------------------------------------------------\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 모델 파라미터\n",
    "# --------------------------------------------------------------------------------\n",
    "hidden_size   = 5\n",
    "window_size   = 3\n",
    "batch_size    = 4\n",
    "num_epochs    = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# Mobius 플랫폼 설정\n",
    "# --------------------------------------------------------------------------------\n",
    "OFFERED_URL = \"203.250.148.120:20519\"\n",
    "MOBIUS_BASE_URL    = f\"http://{OFFERED_URL}/Mobius/\"\n",
    "MOBIUS_AE_NAME     = \"AIOTclass-TS-Trainset\"\n",
    "MOBIUS_TEST_NAME   = \"AIOTclass-TS-Testset\"\n",
    "\n",
    "MOBIUS_BASE_AE_URL  = os.path.join(MOBIUS_BASE_URL, MOBIUS_AE_NAME)\n",
    "MOBIUS_TEST_AE_URL  = os.path.join(MOBIUS_BASE_URL, MOBIUS_TEST_NAME)\n",
    "HEADERS_GET = {\n",
    "    'Accept':       'application/json',\n",
    "    'X-M2M-RI':     '12345',\n",
    "    'X-M2M-Origin': 'SOrigin'\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 센서 컨테이너 이름\n",
    "# --------------------------------------------------------------------------------\n",
    "CONTAINERS = {\n",
    "    \"precipitation\": \"precipitation_sensor\",\n",
    "    \"temperature\":   \"temperature_sensor\",\n",
    "    \"wind\":          \"wind_sensor\",\n",
    "    \"ground_truth\":  \"ground_truth\"\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (1) HTTP 요청 및 데이터 가져오기\n",
    "# --------------------------------------------------------------------------------\n",
    "def http_get(url, params=None, headers=None, iotPlatform=None):\n",
    "    \"\"\"\n",
    "    주어진 URL에 GET 요청을 보내고, 결과를 JSON(dict)로 반환한다.\n",
    "    iotPlatform=True이면 OneM2M용 기본 헤더가 적용된다.\n",
    "    \"\"\"\n",
    "    if iotPlatform:\n",
    "        headers = {\n",
    "            'Accept':       'application/json',\n",
    "            'X-M2M-RI':     '12345',\n",
    "            'X-M2M-Origin': 'SOrigin'\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return json.loads(response.text)\n",
    "\n",
    "    except requests.ConnectTimeout:\n",
    "        print(f\"Connection timed out for URL: {url}\")\n",
    "        return None\n",
    "\n",
    "    except requests.HTTPError as http_err:\n",
    "        print(f\"HTTP error occurred for URL {url}: {http_err}\")\n",
    "        return None\n",
    "\n",
    "    except Exception as err:\n",
    "        print(f\"An error occurred for URL {url}: {err}\")\n",
    "        return None\n",
    "\n",
    "def all_cin_get_uri(path, max_retries=10):\n",
    "    \"\"\"\n",
    "    주어진 컨테이너 경로에서 모든 콘텐츠 인스턴스(CIN) URI를 얻어\n",
    "    각각을 GET하여 'con' 필드를 모아 리스트로 반환한다.\n",
    "    \"\"\"\n",
    "    path = path + '?fu=1&ty=4'  # 모든 CIN(ResourceType=4) 조회 쿼리\n",
    "    parsed_path = urlparse(path)\n",
    "    base_path   = f\"{parsed_path.scheme}://{parsed_path.netloc}/\"\n",
    "\n",
    "    con_list = []\n",
    "    all_uri  = http_get(path, iotPlatform=True)\n",
    "    if not all_uri:\n",
    "        return con_list  # 에러 시 빈 리스트 반환\n",
    "\n",
    "    # 각 URI에 대해 실제 데이터 GET\n",
    "    for uri in all_uri[\"m2m:uril\"]:\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            cin = http_get(base_path + uri, iotPlatform=True)\n",
    "            if cin is not None:\n",
    "                con_list.append(cin[\"m2m:cin\"][\"con\"])\n",
    "                break\n",
    "            else:\n",
    "                retries += 1\n",
    "                print(f\"[Retry {retries}] for URL: {base_path + uri}\")\n",
    "\n",
    "        if retries == max_retries:\n",
    "            print(f\"[FAIL] Data not fetched after {max_retries} attempts for URL: {base_path + uri}\")\n",
    "\n",
    "    return con_list\n",
    "\n",
    "def fetch_data(base_url):\n",
    "    \"\"\"\n",
    "    base_url 하위의 각 컨테이너(CONTAINERS)로부터 데이터를 가져와 dict 형태로 반환한다.\n",
    "    ground_truth 컨테이너는 weather 필드만 추출한다.\n",
    "    \"\"\"\n",
    "    data = {key: [] for key in CONTAINERS.keys()}\n",
    "    for key, container in CONTAINERS.items():\n",
    "        url = f\"{base_url}/{container}\"\n",
    "        con_list = all_cin_get_uri(url)\n",
    "\n",
    "        # 가져온 con_list를 data dict에 저장\n",
    "        for con in con_list:\n",
    "            if key == \"ground_truth\":\n",
    "                # 'weather' 필드만 추출\n",
    "                data[key].append(con['weather'])\n",
    "            else:\n",
    "                # date 이외의 필드를 리스트로 묶어서 저장\n",
    "                data[key].append([con[k] for k in con.keys() if k != \"date\"])\n",
    "    return data\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (2) 데이터 전처리(슬라이딩 윈도우, 스케일링, 원-핫 인코딩 등)\n",
    "# --------------------------------------------------------------------------------\n",
    "def preprocess_data(data, window_size):\n",
    "    \"\"\"\n",
    "    data(dict)에서 precipitation, temperature, wind, ground_truth를 가져와\n",
    "    - MinMaxScaler로 스케일링\n",
    "    - weather(문자열)에 대해 OneHotEncoder 적용\n",
    "    - window_size만큼 시계열 슬라이싱\n",
    "    \"\"\"\n",
    "    # (a) NumPy 배열 변환\n",
    "    precipitation = np.array(data[\"precipitation\"])\n",
    "    temperature   = np.array(data[\"temperature\"])\n",
    "    wind          = np.array(data[\"wind\"])\n",
    "    weather       = np.array(data[\"ground_truth\"])  # 문자열 배열\n",
    "\n",
    "    # (b) MinMax 정규화\n",
    "    scaler = MinMaxScaler()\n",
    "    precipitation = scaler.fit_transform(precipitation)\n",
    "    temperature   = scaler.fit_transform(temperature)\n",
    "    wind          = scaler.fit_transform(wind)\n",
    "\n",
    "    # (c) One-hot 인코딩(날씨 레이블)\n",
    "    encoder         = OneHotEncoder(sparse_output=False)\n",
    "    weather_encoded = encoder.fit_transform(weather.reshape(-1, 1))\n",
    "    \n",
    "    # # 클래스(레이블) 목록 출력\n",
    "    print(\"Categories:\", encoder.categories_)  # (O)\n",
    "    # 예: Categories: [array(['drizzle', 'fog', 'rain', 'snow', 'sun'], dtype='<U7')]\n",
    "\n",
    "    # (d) 슬라이딩 윈도우(X, y) 생성\n",
    "    X, y = [], []\n",
    "    for i in range(len(precipitation) - window_size):\n",
    "        features = np.concatenate([\n",
    "            precipitation[i:i+window_size],\n",
    "            temperature[i:i+window_size],\n",
    "            wind[i:i+window_size]\n",
    "        ], axis=1)\n",
    "        X.append(features)\n",
    "        y.append(weather_encoded[i+window_size])\n",
    "\n",
    "    return np.array(X), np.array(y), scaler, encoder\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (3) 모델 정의 (LSTM)\n",
    "# --------------------------------------------------------------------------------\n",
    "class WeatherLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    입력 시퀀스로부터 날씨 분류(One-hot 형태)를 수행하는 간단한 LSTM 모델.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(WeatherLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc   = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x.shape: (batch, seq_len, input_size)\n",
    "        LSTM 출력 중 마지막 타임스텝(hidden state)을 fully connected로 연결.\n",
    "        \"\"\"\n",
    "        out, _ = self.lstm(x)\n",
    "        out    = self.fc(out[:, -1, :])  # 마지막 타임스텝의 출력만 사용\n",
    "        return out\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (4) 학습 함수\n",
    "# --------------------------------------------------------------------------------\n",
    "def train_model(hidden_size=100, window_size=5, batch_size=32, num_epochs=100, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    - Mobius에서 훈련 데이터(MOBIUS_BASE_AE_URL) 가져오기\n",
    "    - 전처리 후 PyTorch DataLoader 생성\n",
    "    - WeatherLSTM 모델 학습\n",
    "    - 모델 파라미터 저장(weather_lstm_model.pth)\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Fetching training data...\")\n",
    "    train_data = fetch_data(MOBIUS_BASE_AE_URL)\n",
    "    print(\"[INFO] Preprocessing training data...\")\n",
    "    print(train_data)\n",
    "    \n",
    "    print(\"[INFO] Preprocessing training data...\")\n",
    "    X_train, y_train, scaler, encoder = preprocess_data(train_data, window_size)\n",
    "\n",
    "    # 텐서 변환 및 DataLoader 생성\n",
    "    train_dataset = TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # 모델/손실함수/최적화함수 정의\n",
    "    input_size  = X_train.shape[2]\n",
    "    output_size = y_train.shape[1]\n",
    "    print(f\"[INFO] Input size: {input_size}, Output size: {output_size}\")\n",
    "    input()\n",
    "    model = WeatherLSTM(input_size, hidden_size, output_size)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 학습 루프\n",
    "    print(\"[INFO] Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)                       # (batch, output_size)\n",
    "            loss    = criterion(outputs, torch.argmax(y_batch, dim=1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss:.4f}\")\n",
    "\n",
    "    # 학습 완료 후 모델 저장\n",
    "    torch.save(model.state_dict(), \"weather_lstm_model.pth\")\n",
    "    print(\"[INFO] Model trained and saved: weather_lstm_model.pth\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (5) 테스트 함수\n",
    "# --------------------------------------------------------------------------------\n",
    "def test_model(hidden_size=100, window_size=5):\n",
    "    \"\"\"\n",
    "    - Mobius에서 테스트 데이터(MOBIUS_TEST_AE_URL) 가져오기\n",
    "    - 전처리 후 PyTorch DataLoader 생성\n",
    "    - 저장된 모델 가중치 로드(weather_lstm_model.pth)\n",
    "    - 모델 성능 측정(손실, 정확도)\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Fetching test data...\")\n",
    "    test_data = fetch_data(MOBIUS_TEST_AE_URL)\n",
    "\n",
    "    print(\"[INFO] Preprocessing test data...\")\n",
    "    X_test, y_test, scaler, encoder = preprocess_data(test_data, window_size)\n",
    "\n",
    "    # 텐서 변환 및 DataLoader 생성\n",
    "    test_dataset = TensorDataset(\n",
    "        torch.tensor(X_test, dtype=torch.float32),\n",
    "        torch.tensor(y_test, dtype=torch.float32)\n",
    "    )\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # 모델 준비 (동일 구조)\n",
    "    input_size  = X_test.shape[2]\n",
    "    output_size = y_test.shape[1]\n",
    "    model       = WeatherLSTM(input_size, hidden_size, output_size)\n",
    "    model.load_state_dict(torch.load(\"weather_lstm_model.pth\"))\n",
    "    model.eval()\n",
    "\n",
    "    # 평가\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0.0\n",
    "    correct    = 0\n",
    "    total      = 0\n",
    "\n",
    "    print(\"[INFO] Starting evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader:\n",
    "            outputs = model(X_batch)  \n",
    "            loss    = criterion(outputs, torch.argmax(y_batch, dim=1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            predicted = torch.argmax(outputs, dim=1)\n",
    "            correct  += (predicted == torch.argmax(y_batch, dim=1)).sum().item()\n",
    "            total    += y_batch.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "    print(f\"[RESULT] Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# 메인 실행부\n",
    "# --------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"[MAIN] Training model...\")\n",
    "    train_model(hidden_size, window_size, batch_size, num_epochs, learning_rate)\n",
    "\n",
    "    print(\"[MAIN] Testing model...\")\n",
    "    test_model(hidden_size, window_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
