{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ef9c7c-1c01-4bb8-948f-8683e027db7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import socket\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import base64\n",
    "import json\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (1) Mobius 관련 설정\n",
    "# --------------------------------------------------------------------------------\n",
    "MOBIUS_BASE_URL = \"http://203.250.148.120:20519/Mobius/\"\n",
    "MOBIUS_AE_NAME  = \"test-OC\"\n",
    "\n",
    "MOBIUS_SENSOR_DATA_CNT_NAME       = \"sensor_data\"\n",
    "MOBIUS_INFERENCING_RESULT_CNT_NAME= \"inferencing_result\"\n",
    "MOBIUS_MODEL_REPOSITORY_CNT_NAME  = \"model_repository\"\n",
    "\n",
    "MOBIUS_BASE_AE_URL = os.path.join(MOBIUS_BASE_URL, MOBIUS_AE_NAME)\n",
    "\n",
    "# Mobius 업로드 시 사용될 헤더 (콘텐츠 인스턴스 생성)\n",
    "HEADERS_CIN = {\n",
    "    'Accept': 'application/json',\n",
    "    'X-M2M-RI': '12345',\n",
    "    'X-M2M-Origin': 'SOrigin',\n",
    "    'Content-Type': 'application/vnd.onem2m-res+json; ty=4'\n",
    "}\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (2) Mobius 연동 함수\n",
    "# --------------------------------------------------------------------------------\n",
    "def http_get(url, params=None, headers=None, iotPlatform=False):\n",
    "    \"\"\"\n",
    "    - iotPlatform=True이면 OneM2M 관련 헤더 자동 적용\n",
    "    - GET 요청 후 JSON 반환\n",
    "    \"\"\"\n",
    "    if iotPlatform:\n",
    "        headers = {\n",
    "            'Accept': 'application/json',\n",
    "            'X-M2M-RI': '12345',\n",
    "            'X-M2M-Origin': 'SOrigin'\n",
    "        }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, params=params, headers=headers, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[Mobius Error] GET {url} : {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def all_cin_get_uri(path, max_retries=5):\n",
    "    \"\"\"\n",
    "    - path + '?fu=1&ty=4'로 모든 CIN URI 가져옴\n",
    "    - 각각에 대해 GET → 'con' 필드 수집\n",
    "    \"\"\"\n",
    "    path += \"?fu=1&ty=4\"\n",
    "    parsed = urlparse(path)\n",
    "    base_path = f\"{parsed.scheme}://{parsed.netloc}/\"\n",
    "\n",
    "    con_list = []\n",
    "    all_uri  = http_get(path, iotPlatform=True)\n",
    "    if not all_uri or \"m2m:uril\" not in all_uri:\n",
    "        return con_list\n",
    "\n",
    "    for uri in all_uri[\"m2m:uril\"]:\n",
    "        retries = 0\n",
    "        while retries < max_retries:\n",
    "            cin_json = http_get(base_path + uri, iotPlatform=True)\n",
    "            if cin_json is not None and \"m2m:cin\" in cin_json:\n",
    "                con = cin_json[\"m2m:cin\"][\"con\"]\n",
    "                con_list.append(con)\n",
    "                break\n",
    "            else:\n",
    "                retries += 1\n",
    "                print(f\"[Mobius] Retry {retries} for {base_path + uri}\")\n",
    "    return con_list\n",
    "\n",
    "\n",
    "def decode_model(base64_str, save_path=\"./mnist_cnn.pth\"):\n",
    "    \"\"\"\n",
    "    - Base64 문자열을 받아 .pth 모델 파일로 저장\n",
    "    - 저장 경로 반환\n",
    "    \"\"\"\n",
    "    decoded_bytes = base64.b64decode(base64_str)\n",
    "    with open(save_path, \"wb\") as f:\n",
    "        f.write(decoded_bytes)\n",
    "    return save_path\n",
    "\n",
    "\n",
    "def upload_data(sensor_name, data, base_url):\n",
    "    \"\"\"\n",
    "    base_url 아래 sensor_name 컨테이너에 'data'를 콘텐츠 인스턴스(CIN) 형태로 업로드한다.\n",
    "    \"\"\"\n",
    "    url  = f\"{base_url}/{sensor_name}\"\n",
    "    body = {\n",
    "        \"m2m:cin\": {\n",
    "            \"con\": data\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=HEADERS_CIN, json=body)\n",
    "    if response.status_code in [200, 201]:\n",
    "        print(f\"[OK] Data uploaded to '{sensor_name}' at {base_url}.\")\n",
    "    else:\n",
    "        print(f\"[FAIL] Upload data to '{sensor_name}' at {base_url}: {response.text}\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (3) 모델 정의 (예: MNISTCNN)\n",
    "# --------------------------------------------------------------------------------\n",
    "class MNISTCNN(nn.Module):\n",
    "    def __init__(self, output_size=10):\n",
    "        super(MNISTCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1   = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2   = nn.Linear(128, output_size)\n",
    "        self.pool  = nn.MaxPool2d(2, 2)\n",
    "        self.relu  = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (4) 이미지 전처리 함수 (Base64 → 텐서)\n",
    "# --------------------------------------------------------------------------------\n",
    "def preprocess_image_bytes(b64_str):\n",
    "    \"\"\"\n",
    "    - Base64 문자열(b64_str)을 받아,\n",
    "      1) base64 디코딩 → 2) BytesIO → 3) PIL.Image\n",
    "      4) 28×28 흑백으로 변환 → 5) NumPy → 6) PyTorch 텐서\n",
    "    - 최종 shape: (1, 1, 28, 28)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 1) base64 → bytes\n",
    "        img_bytes = base64.b64decode(b64_str)\n",
    "        # 2) BytesIO → PIL\n",
    "        pil_image = Image.open(BytesIO(img_bytes)).convert(\"L\")\n",
    "        # 3) 28×28 리사이즈 (MNIST)\n",
    "        pil_image = pil_image.resize((28, 28))\n",
    "        # 4) [0~255] 범위 유지 (정규화 제거)\n",
    "        arr = np.array(pil_image).astype(np.float32)\n",
    "        # 5) (H, W) → (1, 1, H, W)\n",
    "        tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(0)  # [1, 1, 28, 28]\n",
    "        return tensor\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] preprocess_image_bytes failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# --------------------------------------------------------------------------------\n",
    "# (5) 메인: 소켓 서버 + Mobius 모델 로드\n",
    "# --------------------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # 1) Mobius에서 최신 모델 가져오기\n",
    "    model_repo_path = f"{MOBIUS_BASE_AE_URL}/{MOBIUS_MODEL_REPOSITORY_CNT_NAME}",
    "    con_list = all_cin_get_uri(model_repo_path)\n",
    "    if not con_list:\n",
    "        print(\"[Error] No model data in Mobius.\")\n",
    "        exit(1)\n",
    "\n",
    "    # 1.1) 가장 최근에 올라온 모델(con_list[-1]) 사용\n",
    "    latest_model_data = con_list[-1]  # {\"metadata\": {...}, \"model_file\": \"...(base64)...\" }\n",
    "    base64_model_str  = latest_model_data[\"model_file\"]\n",
    "    metadata          = latest_model_data[\"metadata\"]\n",
    "\n",
    "    # 1.2) 디코딩 → 로컬에 저장\n",
    "    model_path = decode_model(base64_model_str, save_path=\"./mnist_cnn.pth\")\n",
    "\n",
    "    # 1.3) 모델 로드\n",
    "    model = MNISTCNN(output_size=10)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"[MODEL SERVER] Loaded model: {metadata['model_name']} (version {metadata['version']})\")\n",
    "\n",
    "    # 2) 소켓 서버 준비\n",
    "    host = '127.0.0.1'\n",
    "    port = 5000\n",
    "\n",
    "    server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    server_socket.bind((host, port))\n",
    "    server_socket.listen(1)\n",
    "    print(f\"[MODEL SERVER] Listening on {host}:{port}\")\n",
    "\n",
    "    # 3) 연결 대기 → 연결 시 데이터 수신/추론\n",
    "    while True:\n",
    "        conn, addr = server_socket.accept()\n",
    "        print(f\"[MODEL SERVER] Connected by {addr}\")\n",
    "\n",
    "        while True:\n",
    "            # 4) 센서(또는 클라이언트)로부터 메시지 수신 (JSON string)\n",
    "            data = conn.recv(4096).decode('utf-8')\n",
    "            if not data:\n",
    "                break\n",
    "\n",
    "            try:\n",
    "                msg = json.loads(data)\n",
    "            except Exception as e:\n",
    "                print(\"[MODEL SERVER] JSON decode error:\", e)\n",
    "                break\n",
    "\n",
    "            # (4.1) 센서 데이터를 Mobius의 sensor_data 컨테이너에 업로드\n",
    "            sensor_data_con = {\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "                \"raw_base64\": msg.get(\"image_data\", \"\"),  # 원한다면 Base64를 그대로 보관\n",
    "            }\n",
    "            upload_data(MOBIUS_SENSOR_DATA_CNT_NAME, sensor_data_con, MOBIUS_BASE_AE_URL)\n",
    "\n",
    "            # (4.2) 추론\n",
    "            b64_str    = msg.get(\"image_data\", \"\")\n",
    "            image_tensor = preprocess_image_bytes(b64_str)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(image_tensor)\n",
    "                pred   = torch.argmax(output).item()\n",
    "\n",
    "            # (4.3) 추론 결과\n",
    "            result_data = {\n",
    "                \"prediction\": pred,\n",
    "                \"timestamp\": datetime.now().isoformat()\n",
    "            }\n",
    "\n",
    "            # (4.4) 추론 결과를 Mobius의 inferencing_result 컨테이너에 업로드\n",
    "            upload_data(MOBIUS_INFERENCING_RESULT_CNT_NAME, result_data, MOBIUS_BASE_AE_URL)\n",
    "\n",
    "            # (4.5) 응답(추론 결과) 소켓으로 전송\n",
    "            print(f\"[MODEL SERVER] Prediction: {pred}\")\n",
    "            result_json = json.dumps(result_data)\n",
    "            conn.sendall(result_json.encode('utf-8'))\n",
    "\n",
    "        # 연결 종료\n",
    "        conn.close()\n",
    "        print(f\"[MODEL SERVER] Connection closed by {addr}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
